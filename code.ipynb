{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e14238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed9ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39574c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc88f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba509a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGService:\n",
    "    def __init__(self, llm_model : str = 'llama3', embedding_model : str = 'llama3'):\n",
    "        self.llm_model = llm_model\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "        # Initialize emebedding and LLM\n",
    "        self.embeddings = OllamaEmbeddings(model=self.embedding_model)\n",
    "        self.llm = ChatOllama(model=self.llm_model)\n",
    "\n",
    "        # Vector store \n",
    "        self.vector_store = None\n",
    "        self.retriever = None\n",
    "        self.chain = None \n",
    "\n",
    "    def process_url(self, url : str):\n",
    "        try:\n",
    "            loader = WebBaseLoader(url)\n",
    "            docs = loader.load()\n",
    "        except:\n",
    "            raise ValueError(f\"Could not load the URL: {url}\")\n",
    "\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size = 1000,\n",
    "            chunk_overlap = 200\n",
    "        )\n",
    "\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "\n",
    "        if self.vector_store:\n",
    "            self.vector_store.delete_collection()\n",
    "        self.vector_store = Chroma.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=self.embeddings,\n",
    "            collection_name='current_doc'\n",
    "        )\n",
    "    \n",
    "        self.retriever = self.vector_store.as_retriever()\n",
    "        self._create_chain()\n",
    "\n",
    "        return len(splits)\n",
    "    \n",
    "    # \n",
    "    def _create_chain(self):\n",
    "        template = \"\"\"\n",
    "                ROLE:\n",
    "                You are an academic knowledge assistant. Your mission is to transform raw text into high-quality pedagogical materials (flashcards).\n",
    "\n",
    "                TASK:\n",
    "                Analyze the provided context and generate flashcards optimized for spaced repetition based on the user's request.\n",
    "\n",
    "                GOALS:\n",
    "                1. Extract core definitions, core information, and scientific concepts.\n",
    "                2. Focus on single, atomic facts for better memory retention.\n",
    "                3. Use precise, objective academic language.\n",
    "                4. Output strictly as a JSON object (list of dictionaries with \"question\" and \"answer\").\n",
    "\n",
    "                CONTEXT (SOURCE MATERIAL):\n",
    "                {context}\n",
    "\n",
    "                RULES:\n",
    "                - Do NOT add information that is not present in the CONTEXT documents.\n",
    "                - IGNORE metadata like edit dates, licensing info, or source citations, etc.\n",
    "                - If facts are missing, do not invent information.\n",
    "                - NO conversational fillers (e.g., \"Here are your flashcards\" etc.). Output ONLY the JSON.\n",
    "\n",
    "                USER REQUEST:\n",
    "                {question}\n",
    "                \"\"\"\n",
    "        \n",
    "        prompt = ChatPromptTemplate(template)\n",
    "\n",
    "        def format_docs(docs):\n",
    "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "        self.chain = (\n",
    "            {'context': self.retriever | format_docs, \"question\" : RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    \n",
    "    def ask_question(self, question : str) -> str:\n",
    "        if not self.chain:\n",
    "            return \"Please process a ...\"\n",
    "        return self.chain.invoke(question)\n",
    "    \n",
    "\n",
    "rag_server = RAGService()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a139ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
